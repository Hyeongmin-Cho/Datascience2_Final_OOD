{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utility classes for NICE.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import nice, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "def save_list(data, path):\n",
    "    with open(path, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(data, fp)\n",
    "        \n",
    "def load_list(path):\n",
    "    with open(path, \"rb\") as fp:   # Unpickling\n",
    "        b = pickle.load(fp)\n",
    "        return b\n",
    "\n",
    "\"\"\"Additive coupling layer.\n",
    "\"\"\"\n",
    "class Coupling(nn.Module):\n",
    "    def __init__(self, in_out_dim, mid_dim, hidden, mask_config):\n",
    "        \"\"\"Initialize a coupling layer.\n",
    "\n",
    "        Args:\n",
    "            in_out_dim: input/output dimensions.\n",
    "            mid_dim: number of units in a hidden layer.\n",
    "            hidden: number of hidden layers.\n",
    "            mask_config: 1 if transform odd units, 0 if transform even units.\n",
    "        \"\"\"\n",
    "        super(Coupling, self).__init__()\n",
    "        self.mask_config = mask_config\n",
    "\n",
    "        self.in_block = nn.Sequential(\n",
    "            nn.Linear(in_out_dim//2, mid_dim),\n",
    "            nn.ReLU())\n",
    "        self.mid_block = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(mid_dim, mid_dim),\n",
    "                nn.ReLU()) for _ in range(hidden - 1)])\n",
    "        self.out_block = nn.Linear(mid_dim, in_out_dim//2)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x: input tensor.\n",
    "            reverse: True in inference mode, False in sampling mode.\n",
    "        Returns:\n",
    "            transformed tensor.\n",
    "        \"\"\"\n",
    "        [B, W] = list(x.size())\n",
    "        x = x.reshape((B, W//2, 2))\n",
    "        if self.mask_config:\n",
    "            on, off = x[:, :, 0], x[:, :, 1]\n",
    "        else:\n",
    "            off, on = x[:, :, 0], x[:, :, 1]\n",
    "\n",
    "        off_ = self.in_block(off)\n",
    "        for i in range(len(self.mid_block)):\n",
    "            off_ = self.mid_block[i](off_)\n",
    "        shift = self.out_block(off_)\n",
    "        if reverse:\n",
    "            on = on - shift\n",
    "        else:\n",
    "            on = on + shift\n",
    "\n",
    "        if self.mask_config:\n",
    "            x = torch.stack((on, off), dim=2)\n",
    "        else:\n",
    "            x = torch.stack((off, on), dim=2)\n",
    "        return x.reshape((B, W))\n",
    "\n",
    "\"\"\"Log-scaling layer.\n",
    "\"\"\"\n",
    "class Scaling(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        \"\"\"Initialize a (log-)scaling layer.\n",
    "\n",
    "        Args:\n",
    "            dim: input/output dimensions.\n",
    "        \"\"\"\n",
    "        super(Scaling, self).__init__()\n",
    "        self.scale = nn.Parameter(\n",
    "            torch.zeros((1, dim)), requires_grad=True)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x: input tensor.\n",
    "            reverse: True in inference mode, False in sampling mode.\n",
    "        Returns:\n",
    "            transformed tensor and log-determinant of Jacobian.\n",
    "        \"\"\"\n",
    "        log_det_J = torch.sum(self.scale)\n",
    "        if reverse:\n",
    "            x = x * torch.exp(-self.scale)\n",
    "        else:\n",
    "            x = x * torch.exp(self.scale)\n",
    "        return x, log_det_J\n",
    "\n",
    "\"\"\"NICE main model.\n",
    "\"\"\"\n",
    "class NICE(nn.Module):\n",
    "    def __init__(self, prior, coupling, \n",
    "        fc_in_dim, in_out_dim, mid_dim, hidden, mask_config):\n",
    "        \"\"\"Initialize a NICE.\n",
    "\n",
    "        Args:\n",
    "            prior: prior distribution over latent space Z.\n",
    "            coupling: number of coupling layers.\n",
    "            in_out_dim: input/output dimensions.\n",
    "            mid_dim: number of units in a hidden layer.\n",
    "            hidden: number of hidden layers.\n",
    "            mask_config: 1 if transform odd units, 0 if transform even units.\n",
    "        \"\"\"\n",
    "        super(NICE, self).__init__()\n",
    "        self.prior = prior\n",
    "        self.in_out_dim = in_out_dim\n",
    "        self.fc_in_dim = fc_in_dim\n",
    "        self.coupling = nn.ModuleList([\n",
    "            Coupling(in_out_dim=in_out_dim, \n",
    "                     mid_dim=mid_dim, \n",
    "                     hidden=hidden, \n",
    "                     mask_config=(mask_config+i)%2) \\\n",
    "            for i in range(coupling)])\n",
    "        self.scaling = Scaling(in_out_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(fc_in_dim, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, in_out_dim)\n",
    "        )\n",
    "\n",
    "    def g(self, z):\n",
    "        \"\"\"Transformation g: Z -> X (inverse of f).\n",
    "\n",
    "        Args:\n",
    "            z: tensor in latent space Z.\n",
    "        Returns:\n",
    "            transformed tensor in data space X.\n",
    "        \"\"\"\n",
    "        x, _ = self.scaling(z, reverse=True)\n",
    "        for i in reversed(range(len(self.coupling))):\n",
    "            x = self.coupling[i](x, reverse=True)\n",
    "        return x\n",
    "\n",
    "    def f(self, x):\n",
    "        \"\"\"Transformation f: X -> Z (inverse of g).\n",
    "\n",
    "        Args:\n",
    "            x: tensor in data space X.\n",
    "        Returns:\n",
    "            transformed tensor in latent space Z.\n",
    "        \"\"\"\n",
    "        for i in range(len(self.coupling)):\n",
    "            x = self.coupling[i](x)\n",
    "        return self.scaling(x)\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        \"\"\"Computes data log-likelihood.\n",
    "\n",
    "        (See Section 3.3 in the NICE paper.)\n",
    "\n",
    "        Args:\n",
    "            x: input minibatch.\n",
    "        Returns:\n",
    "            log-likelihood of input.\n",
    "        \"\"\"\n",
    "#         semantic_z = self.fc(x)\n",
    "        z, log_det_J = self.f(x)\n",
    "        log_ll = torch.sum(self.prior.log_prob(z), dim=1)\n",
    "        return log_ll + log_det_J\n",
    "\n",
    "    def sample(self, size):\n",
    "        \"\"\"Generates samples.\n",
    "\n",
    "        Args:\n",
    "            size: number of samples to generate.\n",
    "        Returns:\n",
    "            samples from the data space X.\n",
    "        \"\"\"\n",
    "        z = self.prior.sample((size, self.in_out_dim)).cuda()\n",
    "        return self.g(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x: input minibatch.\n",
    "        Returns:\n",
    "            log-likelihood of input.\n",
    "        \"\"\"\n",
    "        return self.log_prob(x)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a coupling layer.\n",
    "\n",
    "        Args:\n",
    "            in_out_dim: input/output dimensions.\n",
    "            mid_dim: number of units in a hidden layer.\n",
    "            hidden: number of hidden layers.\n",
    "            mask_config: 1 if transform odd units, 0 if transform even units.\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 2, stride=3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 2, stride=3)\n",
    "        self.fc1 = nn.Linear(32 * 3 *3, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x, reverse=False):\n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = x.reshape(-1, 32 * 3 *3)\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        embd = x\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x)\n",
    "        return x, embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:227: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1000: loss = 216.652 bits/dim = 10.442\n",
      "iter 2000: loss = 167.700 bits/dim = 9.890\n",
      "iter 3000: loss = 148.281 bits/dim = 9.671\n",
      "iter 4000: loss = 135.019 bits/dim = 9.522\n",
      "iter 5000: loss = 125.547 bits/dim = 9.415\n",
      "iter 6000: loss = 118.176 bits/dim = 9.332\n",
      "iter 7000: loss = 111.626 bits/dim = 9.258\n",
      "iter 8000: loss = 107.021 bits/dim = 9.206\n",
      "iter 9000: loss = 103.130 bits/dim = 9.162\n",
      "iter 10000: loss = 99.165 bits/dim = 9.118\n",
      "iter 11000: loss = 96.443 bits/dim = 9.087\n",
      "iter 12000: loss = 93.926 bits/dim = 9.059\n",
      "iter 13000: loss = 91.408 bits/dim = 9.030\n",
      "iter 14000: loss = 89.516 bits/dim = 9.009\n",
      "iter 15000: loss = 87.820 bits/dim = 8.990\n",
      "Finished training!\n",
      "Checkpoint Saved\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:6\")\n",
    "\n",
    "# model hyperparameters\n",
    "dataset = 'mnist'\n",
    "batch_size = 200\n",
    "latent = 'logistic'\n",
    "max_iter = 15000\n",
    "fc_in_dim = 128\n",
    "sample_size = 64\n",
    "coupling = 4\n",
    "mask_config = 1.\n",
    "\n",
    "# optimization hyperparameters\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "decay = 0.999\n",
    "\n",
    "zca = None\n",
    "mean = None\n",
    "if dataset == 'mnist':\n",
    "    mean = torch.load('./statistics/mnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (128, 500, 5)\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    trainset = torchvision.datasets.MNIST(root='~/torch/data/MNIST',\n",
    "        train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "        batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "elif dataset == 'emnist':\n",
    "    mean = torch.load('./statistics/emnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (128, 500, 5)\n",
    "    emnist_data = load_list('./emnist_test_data.pkl')\n",
    "    emnist_label = load_list('./emnist_test_label.pkl')\n",
    "    trainset = TensorDataset(torch.Tensor(emnist_data), torch.Tensor(emnist_label))\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                    batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "elif dataset == 'fashion-mnist':\n",
    "    mean = torch.load('./statistics/fashion_mnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (128, 500, 5)\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    trainset = torchvision.datasets.FashionMNIST(root='~/torch/data/FashionMNIST',\n",
    "        train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "        batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "if latent == 'normal':\n",
    "    prior = torch.distributions.Normal(\n",
    "        torch.tensor(0.).to(device), torch.tensor(1.).to(device))\n",
    "elif latent == 'logistic':\n",
    "    prior = utils.StandardLogistic()\n",
    "\n",
    "filename = '%s_' % dataset \\\n",
    "         + 'bs%d_' % batch_size \\\n",
    "         + '%s_' % latent \\\n",
    "         + 'cp%d_' % coupling \\\n",
    "         + 'md%d_' % mid_dim \\\n",
    "         + 'hd%d_' % hidden\n",
    "\n",
    "flow = NICE(prior=prior, \n",
    "            coupling=coupling,\n",
    "            fc_in_dim = fc_in_dim,\n",
    "            in_out_dim=full_dim, \n",
    "            mid_dim=mid_dim, \n",
    "            hidden=hidden, \n",
    "            mask_config=mask_config).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    flow.parameters(), lr=lr, betas=(momentum, decay), eps=1e-4)\n",
    "\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('./%s_embd_model.pt'%dataset))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "total_iter = 0\n",
    "train = True\n",
    "running_loss = 0\n",
    "\n",
    "while train:\n",
    "    for _, data in enumerate(trainloader, 1):\n",
    "        flow.train()    # set to training mode\n",
    "        if total_iter == max_iter:\n",
    "            train = False\n",
    "            break\n",
    "\n",
    "        total_iter += 1\n",
    "        optimizer.zero_grad()    # clear gradient tensors\n",
    "\n",
    "        inputs, target = data\n",
    "        inputs = utils.prepare_data(\n",
    "            inputs, dataset, zca=zca, mean=mean).to(device)\n",
    "        inputs = inputs.reshape(-1, 1, 28, 28)\n",
    "        _, inputs = model(inputs)\n",
    "        target = target.long().to(device)\n",
    "\n",
    "        # log-likelihood of input minibatch\n",
    "        loss_output= flow(inputs)\n",
    "#         if dataset == 'emnist':\n",
    "#             loss = -loss_output.mean() + criterion(F.softmax(sematic), target-1)\n",
    "#         else:\n",
    "#             loss = -loss_output.mean() + criterion(F.softmax(sematic), target)\n",
    "        loss = -loss_output.mean()\n",
    "        running_loss += float(loss)\n",
    "\n",
    "        # backprop and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if total_iter % 1000 == 0:\n",
    "            mean_loss = running_loss / 1000\n",
    "            bit_per_dim = (mean_loss + np.log(256.) * full_dim) \\\n",
    "                        / (full_dim * np.log(2.))\n",
    "            print('iter %s:' % total_iter, \n",
    "                'loss = %.3f' % mean_loss, \n",
    "                'bits/dim = %.3f' % bit_per_dim)\n",
    "            running_loss = 0.0\n",
    "\n",
    "#             flow.eval()        # set to inference mode\n",
    "#             with torch.no_grad():\n",
    "#                 z, _ = flow.f(inputs)\n",
    "#                 reconst = flow.g(z).cpu()\n",
    "#                 reconst = utils.prepare_data(\n",
    "#                     reconst, dataset, zca=zca, mean=mean, reverse=True)\n",
    "#                 samples = flow.sample(sample_size).cpu()\n",
    "#                 samples = utils.prepare_data(\n",
    "#                     samples, dataset, zca=zca, mean=mean, reverse=True)\n",
    "#                 torchvision.utils.save_image(torchvision.utils.make_grid(reconst),\n",
    "#                     './reconstruction/' + filename +'iter%d.png' % total_iter)\n",
    "#                 torchvision.utils.save_image(torchvision.utils.make_grid(samples),\n",
    "#                     './samples/' + filename +'iter%d.png' % total_iter)\n",
    "\n",
    "print('Finished training!')\n",
    "\n",
    "torch.save({\n",
    "    'total_iter': total_iter, \n",
    "    'model_state_dict': flow.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict(), \n",
    "    'dataset': dataset, \n",
    "    'batch_size': batch_size, \n",
    "    'latent': latent, \n",
    "    'coupling': coupling, \n",
    "    'mid_dim': mid_dim, \n",
    "    'hidden': hidden, \n",
    "    'mask_config': mask_config}, \n",
    "    './models_aux/%s/'%dataset + filename +'iter%d.tar' % total_iter)\n",
    "\n",
    "print('Checkpoint Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading complete!\n",
      "./models_aux/mnist/mnist_bs200_logistic_cp4_md500_hd5_iter15000.tar\n",
      "Calculating log_prob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:227: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "40it [00:00, 99.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# model hyperparameters\n",
    "dataset = 'emnist'\n",
    "trained_dataset = 'mnist'\n",
    "batch_size = 200\n",
    "latent = 'logistic'\n",
    "max_iter = 15000\n",
    "fc_in_dim = 128\n",
    "sample_size = 64\n",
    "coupling = 4\n",
    "mask_config = 1.\n",
    "\n",
    "# optimization hyperparameters\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "decay = 0.999\n",
    "\n",
    "zca = None\n",
    "mean = None\n",
    "if dataset == 'mnist':\n",
    "    mean = torch.load('./statistics/mnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (128, 500, 5)\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    trainset = torchvision.datasets.MNIST(root='~/torch/data/MNIST',\n",
    "        train=False, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "        batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "elif dataset == 'emnist':\n",
    "    mean = torch.load('./statistics/emnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (128, 500, 5)\n",
    "    emnist_data = load_list('./emnist_test_data.pkl')\n",
    "    emnist_label = load_list('./emnist_test_label.pkl')\n",
    "    trainset = TensorDataset(torch.Tensor(emnist_data), torch.Tensor(emnist_label))\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                    batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "elif dataset == 'fashion-mnist':\n",
    "    mean = torch.load('./statistics/fashion_mnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (128, 500, 5)\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    trainset = torchvision.datasets.FashionMNIST(root='~/torch/data/FashionMNIST',\n",
    "        train=False, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "        batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "if latent == 'normal':\n",
    "    prior = torch.distributions.Normal(\n",
    "        torch.tensor(0.).to(device), torch.tensor(1.).to(device))\n",
    "elif latent == 'logistic':\n",
    "    prior = utils.StandardLogistic()\n",
    "\n",
    "filename = '%s_' % trained_dataset \\\n",
    "         + 'bs%d_' % batch_size \\\n",
    "         + '%s_' % latent \\\n",
    "         + 'cp%d_' % coupling \\\n",
    "         + 'md%d_' % mid_dim \\\n",
    "         + 'hd%d_' % hidden\n",
    "\n",
    "flow = NICE(prior=prior, \n",
    "            coupling=coupling,\n",
    "            fc_in_dim = fc_in_dim,\n",
    "            in_out_dim=full_dim, \n",
    "            mid_dim=mid_dim, \n",
    "            hidden=hidden, \n",
    "            mask_config=mask_config).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    flow.parameters(), lr=lr, betas=(momentum, decay), eps=1e-4)\n",
    "\n",
    "total_iter = 0\n",
    "train = True\n",
    "running_loss = 0\n",
    "loss_list = []\n",
    "\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('./%s_embd_model.pt'%trained_dataset))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print('Model loading complete!')\n",
    "print('./models_aux/%s/%siter%d.tar'%(trained_dataset, filename, max_iter))\n",
    "checkpoints = torch.load('./models_aux/%s/%siter%d.tar'%(trained_dataset, filename, max_iter))\n",
    "flow.load_state_dict(checkpoints['model_state_dict'])\n",
    "print('Calculating log_prob')\n",
    "\n",
    "for _, data in tqdm(enumerate(trainloader, 1)):\n",
    "    flow.eval()\n",
    "    if total_iter == max_iter:\n",
    "        train = False\n",
    "        break\n",
    "\n",
    "    total_iter += 1\n",
    "    optimizer.zero_grad()    # clear gradient tensors\n",
    "\n",
    "    inputs, target = data\n",
    "    inputs = utils.prepare_data(\n",
    "        inputs, dataset, zca=None, mean=mean).to(device)\n",
    "    inputs = inputs.reshape(-1, 1, 28, 28)\n",
    "    _, inputs = model(inputs)\n",
    "    target = target.long().to(device)\n",
    "\n",
    "    # log-likelihood of input minibatch\n",
    "    loss_output= flow(inputs)\n",
    "    \n",
    "    loss_list.append(-loss_output.cpu().data.numpy())\n",
    "    \n",
    "loss_list = np.array(loss_list).reshape(-1)\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([432.8667 , 392.5661 , 339.13953, ..., 487.11993, 266.9073 ,\n",
       "       229.79628], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([432.8667 , 392.5661 , 339.13953, ..., 487.11993, 266.9073 ,\n",
       "       229.79628], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_list(loss_list, './results/aux/train_%s_test_%s_loss.pkl'%(trained_dataset, dataset))\n",
    "load_list('./results/aux/train_%s_test_%s_loss.pkl'%(trained_dataset, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'emnist'\n",
    "batch_size = 100\n",
    "device = 'cuda:4'\n",
    "\n",
    "if dataset == 'mnist':\n",
    "    mean = torch.load('./statistics/mnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (1 * 28 * 28, 1000, 5)\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    trainset = torchvision.datasets.MNIST(root='~/torch/data/MNIST',\n",
    "        train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "        batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "elif dataset == 'emnist':\n",
    "    mean = torch.load('./statistics/emnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (1 * 28 * 28, 1000, 5)\n",
    "    emnist_data = load_list('./emnist_train_data.pkl')\n",
    "    emnist_label = load_list('./emnist_train_label.pkl')\n",
    "    trainset = TensorDataset(torch.Tensor(emnist_data), torch.Tensor(emnist_label))\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "elif dataset == 'fashion-mnist':\n",
    "    mean = torch.load('./statistics/fashion_mnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (1 * 28 * 28, 1000, 5)\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    trainset = torchvision.datasets.FashionMNIST(root='~/torch/data/FashionMNIST',\n",
    "        train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "        batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a coupling layer.\n",
    "\n",
    "        Args:\n",
    "            in_out_dim: input/output dimensions.\n",
    "            mid_dim: number of units in a hidden layer.\n",
    "            hidden: number of hidden layers.\n",
    "            mask_config: 1 if transform odd units, 0 if transform even units.\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 2, stride=3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 2, stride=3)\n",
    "        self.fc1 = nn.Linear(32 * 3 *3, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x, reverse=False):\n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = x.reshape(-1, 32 * 3 *3)\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        embd = x\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x)\n",
    "        return x, embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=0.001, eps=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  2%|▏         | 1/50 [00:02<02:24,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 933.7865806818008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [00:05<02:17,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 850.8915197849274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/50 [00:08<02:15,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 822.8712948560715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [00:11<02:08,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 804.37983751297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/50 [00:13<02:05,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 792.2115323543549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [00:16<01:57,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 783.8098410367966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/50 [00:19<02:04,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 777.7055968046188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [00:22<01:57,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 773.0303585529327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [00:24<01:51,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 769.3047661781311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/50 [00:27<01:48,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 766.1822824478149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [00:29<01:41,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 762.9142169952393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [00:32<01:37,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 760.3056217432022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 13/50 [00:34<01:34,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 758.3159655332565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [00:37<01:34,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 756.2790558338165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [00:40<01:32,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 754.0227473974228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [00:42<01:29,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 752.7859129905701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [00:45<01:26,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 750.8165979385376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 18/50 [00:48<01:24,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 749.4775792360306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [00:50<01:21,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 747.9158524274826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 20/50 [00:53<01:21,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 746.5630462169647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 21/50 [00:56<01:17,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 744.9250929355621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 22/50 [00:58<01:14,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 743.7624547481537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 23/50 [01:01<01:12,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 742.8824466466904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 24/50 [01:04<01:09,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 741.8954775333405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 25/50 [01:07<01:07,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 740.6927067041397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 26/50 [01:09<01:05,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 739.6339681148529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 27/50 [01:12<01:02,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 738.7188880443573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 28/50 [01:15<01:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 737.5434273481369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [01:18<00:57,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 736.8673624992371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [01:20<00:54,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 736.4634869098663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 31/50 [01:23<00:51,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 735.9175111055374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 32/50 [01:25<00:48,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 735.0809383392334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 33/50 [01:28<00:44,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 733.9444080591202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 34/50 [01:31<00:42,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 733.4062818288803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 35/50 [01:33<00:39,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 732.9633536338806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 36/50 [01:36<00:37,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 732.2552486658096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 731.9425407648087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 38/50 [01:41<00:31,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 731.7111604213715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 39/50 [01:44<00:28,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 731.0291463136673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 40/50 [01:46<00:25,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 730.5048418045044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 41/50 [01:49<00:24,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 729.976172208786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 42/50 [01:52<00:21,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 729.3653045892715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 43/50 [01:54<00:18,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 729.1404027938843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [01:57<00:16,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 728.6273589134216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [02:00<00:14,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 728.3801941871643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 46/50 [02:03<00:11,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 728.1932671070099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 47/50 [02:06<00:08,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 727.8758239746094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 48/50 [02:08<00:05,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 727.5501205921173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 49/50 [02:11<00:02,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 727.2476817369461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:14<00:00,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 726.8566207885742\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(50)):\n",
    "    epoch_loss = 0\n",
    "    for _, (inputs, target) in enumerate(trainloader):\n",
    "        model.train()\n",
    "\n",
    "        optimizer.zero_grad()    # clear gradient tensors\n",
    "        inputs = utils.prepare_data(\n",
    "            inputs, dataset, zca=None, mean=mean).to(device)\n",
    "        inputs = inputs.reshape(-1, 1, 28, 28)\n",
    "        target = target.long().to(device)\n",
    "\n",
    "        # log-likelihood of input minibatch\n",
    "        outputs, _ = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, target-1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print('epoch loss:', epoch_loss)\n",
    "        \n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.to('cpu').state_dict(), './emnist_embd_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'emnist'\n",
    "batch_size = 100\n",
    "device = 'cuda:6'\n",
    "\n",
    "if dataset == 'mnist':\n",
    "    mean = torch.load('./statistics/mnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (1 * 28 * 28, 1000, 5)\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    trainset = torchvision.datasets.MNIST(root='~/torch/data/MNIST',\n",
    "        train=False, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "        batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "elif dataset == 'emnist':\n",
    "    mean = torch.load('./statistics/emnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (1 * 28 * 28, 1000, 5)\n",
    "    emnist_data = load_list('./emnist_test_data.pkl')\n",
    "    emnist_label = load_list('./emnist_test_label.pkl')\n",
    "    trainset = TensorDataset(torch.Tensor(emnist_data), torch.Tensor(emnist_label))\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "elif dataset == 'fashion-mnist':\n",
    "    mean = torch.load('./statistics/fashion_mnist_mean.pt')\n",
    "    (full_dim, mid_dim, hidden) = (1 * 28 * 28, 1000, 5)\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    trainset = torchvision.datasets.FashionMNIST(root='~/torch/data/FashionMNIST',\n",
    "        train=False, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "        batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(2, 2), stride=(3, 3))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(2, 2), stride=(3, 3))\n",
       "  (fc1): Linear(in_features=288, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('./emnist_embd_model.pt'))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for _, (inputs, target) in enumerate(trainloader):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()    # clear gradient tensors\n",
    "    inputs = utils.prepare_data(\n",
    "        inputs, dataset, zca=None, mean=mean).to(device)\n",
    "    inputs = inputs.reshape(-1, 1, 28, 28)\n",
    "    target = target.long().to(device) -1\n",
    "\n",
    "    # log-likelihood of input minibatch\n",
    "    outputs, embd= model(inputs)\n",
    "\n",
    "    pred = torch.argmax(outputs, axis=1).detach().cpu().numpy()\n",
    "    target = target.detach().cpu().numpy()\n",
    "    correct += (pred == target).sum()\n",
    "     \n",
    "print(correct/len(trainloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
